{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(data):\n",
    "    flattened_data = data.reshape(data.shape[0], -1)\n",
    "    return flattened_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hjorth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_mean(eeg_data):\n",
    "    \"\"\"\n",
    "    Calculate the Hjorth parameters of EEG data and return the mean values across channels for each epoch.\n",
    "    Args:\n",
    "        eeg_data (ndarray): EEG data of shape (number_of_epochs, number_of_channels, number_of_datapoints_per_epoch).\n",
    "    Returns:\n",
    "        mean_activity (ndarray): Mean activity parameter of shape (number_of_epochs,).\n",
    "        mean_mobility (ndarray): Mean mobility parameter of shape (number_of_epochs,).\n",
    "        mean_complexity (ndarray): Mean complexity parameter of shape (number_of_epochs,).\n",
    "    \"\"\"\n",
    "    n_epochs, n_channels, n_datapoints = eeg_data.shape\n",
    "    mean_activity = np.zeros((n_epochs,))\n",
    "    mean_mobility = np.zeros((n_epochs,))\n",
    "    mean_complexity = np.zeros((n_epochs,))\n",
    "    for i in range(n_epochs):\n",
    "        activity = 0\n",
    "        mobility = 0\n",
    "        complexity = 0\n",
    "        for j in range(n_channels):\n",
    "            signal = eeg_data[i, j, :]\n",
    "            diff1 = np.diff(signal)\n",
    "            diff2 = np.diff(signal, n=2)\n",
    "            var_zero = np.var(signal)\n",
    "            var_d1 = np.var(diff1)\n",
    "            var_d2 = np.var(diff2)\n",
    "            activity += var_zero\n",
    "            mobility += np.sqrt(var_d1 / var_zero)\n",
    "            complexity += np.sqrt(var_d2 / var_d1) / np.sqrt(var_d1 / var_zero)\n",
    "        mean_activity[i] = activity / n_channels\n",
    "        mean_mobility[i] = mobility / n_channels\n",
    "        mean_complexity[i] = complexity / n_channels\n",
    "    return mean_activity, mean_mobility, mean_complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis(eeg_data):\n",
    "    num_epochs, num_channels, num_datapoints_per_epoch = eeg_data.shape\n",
    "    result = np.zeros(num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        epoch_data = eeg_data[i, :, :]\n",
    "        epoch_mean = np.mean(epoch_data, axis=1)\n",
    "        epoch_std = np.std(epoch_data, axis=1, ddof=1)\n",
    "        epoch_kurtosis = (\n",
    "            np.mean((epoch_data.T - epoch_mean) ** 4, axis=0) / epoch_std**4 - 3\n",
    "        )\n",
    "        result[i] = np.mean(epoch_kurtosis)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Fetures!\n",
    "### Approx Mean, Approx Std Deviation, Approx Energy, Detailed Mean, Detailed Std Deviation, Detailed Energy, Approx Entropy & Detailed Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_features(epoch):\n",
    "    num_epochs, num_channels, num_samples = epoch.shape\n",
    "    cA_values = np.zeros((num_epochs, num_channels, num_samples // 2))\n",
    "    cD_values = np.zeros((num_epochs, num_channels, num_samples // 2))\n",
    "    cA_mean = np.zeros((num_epochs, num_channels))\n",
    "    cA_std = np.zeros((num_epochs, num_channels))\n",
    "    cA_Energy = np.zeros((num_epochs, num_channels))\n",
    "    cD_mean = np.zeros((num_epochs, num_channels))\n",
    "    cD_std = np.zeros((num_epochs, num_channels))\n",
    "    cD_Energy = np.zeros((num_epochs, num_channels))\n",
    "    Entropy_D = np.zeros((num_epochs, num_channels))\n",
    "    Entropy_A = np.zeros((num_epochs, num_channels))\n",
    "    wfeatures = np.zeros((num_epochs, 7 * num_channels))\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        for j in range(num_channels):\n",
    "            cA, cD = pywt.dwt(epoch[i, j, :], \"coif1\")\n",
    "            # cA_values[i, j, :] = cA\n",
    "            # cD_values[i, j, :] = cD\n",
    "            cA_mean[i, j] = np.mean(cA)\n",
    "            cA_std[i, j] = np.abs(np.std(cA))\n",
    "            cA_Energy[i, j] = np.sum(np.square(cA))\n",
    "            cD_mean[i, j] = np.mean(cD)\n",
    "            cD_std[i, j] = np.abs(np.std(cD))\n",
    "            cD_Energy[i, j] = np.sum(np.square(cD))\n",
    "            Entropy_D[i, j] = np.sum(np.square(cD) * np.log(np.square(cD)))\n",
    "            Entropy_A[i, j] = np.sum(np.square(cA) * np.log(np.square(cA)))\n",
    "\n",
    "    wfeatures[:, 0::7] = cA_mean\n",
    "    wfeatures[:, 1::7] = cA_std\n",
    "    wfeatures[:, 2::7] = cA_Energy\n",
    "    wfeatures[:, 3::7] = cD_mean\n",
    "    wfeatures[:, 4::7] = cD_std\n",
    "    wfeatures[:, 5::7] = cD_Energy\n",
    "    wfeatures[:, 6::7] = Entropy_D + Entropy_A\n",
    "\n",
    "    return wfeatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectral Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPwelch_epochs(epochs, Fs):\n",
    "  n_epochs, n_channels, n_samples_per_epoch = epochs.shape\n",
    "  BandF = [12, 30, 100]\n",
    "  PMax = np.zeros([n_epochs, n_channels, len(BandF) - 1])\n",
    "\n",
    "  for i in range(n_epochs):\n",
    "    for j in range(n_channels):\n",
    "      f, Psd = signal.welch(epochs[i, j, :], Fs)\n",
    "\n",
    "      if np.any(np.isnan(Psd)):\n",
    "        nonnan_values = Psd[~np.isnan(Psd)]\n",
    "        nan_average = np.mean(nonnan_values)\n",
    "        Psd[np.isnan(Psd)] = nan_average\n",
    "\n",
    "      for k in range(len(BandF) - 1):\n",
    "        fr = np.where((f > BandF[k]) & (f <= BandF[k + 1]))\n",
    "        PMax[i, j, k] = np.max(Psd[fr])\n",
    "\n",
    "  return PMax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading preporcessed Data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = np.load(\"./cleaned_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 14, 376)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(epoch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjorth = hjorth_mean(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hjorth_list = np.concatenate(\n",
    "    (hjorth[0][:, np.newaxis], hjorth[1][:, np.newaxis], hjorth[2][:, np.newaxis]),\n",
    "    axis=1,\n",
    ")\n",
    "display(hjorth_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8640,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hjorth[0].shape, hjorth[1].shape, hjorth[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kurtosis = kurtosis(epoch_data)\n",
    "display(kurtosis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 98)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wavelet = wavelet_features(epoch_data)\n",
    "display(wavelet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 14, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "psd = maxPwelch_epochs(epoch_data, 500)\n",
    "display(psd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "psd_2d = flatten(psd)\n",
    "display(psd_2d.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding labels and building the final feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.load(\"./labels.npy\")\n",
    "display(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 131)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_vector = np.concatenate(\n",
    "    (hjorth_list, kurtosis[:, np.newaxis], wavelet, psd_2d, labels[:, np.newaxis]),\n",
    "    axis=1,\n",
    ")\n",
    "display(feature_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"labeled_feature_vector.npy\", feature_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
