{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectid = '28'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hjorth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_mean(eeg_data):\n",
    "    \"\"\"\n",
    "    Calculate the Hjorth parameters of EEG data and return the mean values across channels for each epoch.\n",
    "    Args:\n",
    "        eeg_data (ndarray): EEG data of shape (number_of_epochs, number_of_channels, number_of_datapoints_per_epoch).\n",
    "    Returns:\n",
    "        mean_activity (ndarray): Mean activity parameter of shape (number_of_epochs,).\n",
    "        mean_mobility (ndarray): Mean mobility parameter of shape (number_of_epochs,).\n",
    "        mean_complexity (ndarray): Mean complexity parameter of shape (number_of_epochs,).\n",
    "    \"\"\"\n",
    "    n_epochs, n_channels, n_datapoints = eeg_data.shape\n",
    "    mean_activity = np.zeros((n_epochs,))\n",
    "    mean_mobility = np.zeros((n_epochs,))\n",
    "    mean_complexity = np.zeros((n_epochs,))\n",
    "    for i in range(n_epochs):\n",
    "        activity = 0\n",
    "        mobility = 0\n",
    "        complexity = 0\n",
    "        for j in range(n_channels):\n",
    "            signal = eeg_data[i, j, :]\n",
    "            diff1 = np.diff(signal)\n",
    "            diff2 = np.diff(signal, n=2)\n",
    "            var_zero = np.var(signal)\n",
    "            var_d1 = np.var(diff1)\n",
    "            var_d2 = np.var(diff2)\n",
    "            activity += var_zero\n",
    "            mobility += np.sqrt(var_d1 / var_zero)\n",
    "            complexity += np.sqrt(var_d2 / var_d1) / np.sqrt(var_d1 / var_zero)\n",
    "        mean_activity[i] = activity / n_channels\n",
    "        mean_mobility[i] = mobility / n_channels\n",
    "        mean_complexity[i] = complexity / n_channels\n",
    "    return mean_activity, mean_mobility, mean_complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis_feature(eeg_data):\n",
    "    num_epochs, num_channels, num_datapoints_per_epoch = eeg_data.shape\n",
    "    result = np.zeros(num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        epoch_data = eeg_data[i, :, :]\n",
    "        epoch_mean = np.mean(epoch_data, axis=1)\n",
    "        epoch_std = np.std(epoch_data, axis=1, ddof=1)\n",
    "        epoch_kurtosis = (\n",
    "            np.mean((epoch_data.T - epoch_mean) ** 4, axis=0) / epoch_std**4 - 3\n",
    "        )\n",
    "        result[i] = np.mean(epoch_kurtosis)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Fetures!\n",
    "### Approx Mean, Approx Std Deviation, Approx Energy, Detailed Mean, Detailed Std Deviation, Detailed Energy, Approx Entropy & Detailed Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_features(epoch):\n",
    "    num_epochs, num_channels, num_samples = epoch.shape\n",
    "    cA_values = np.zeros((num_epochs, num_channels, num_samples // 2))\n",
    "    cD_values = np.zeros((num_epochs, num_channels, num_samples // 2))\n",
    "    cA_mean = np.zeros((num_epochs, num_channels))\n",
    "    cA_std = np.zeros((num_epochs, num_channels))\n",
    "    cA_Energy = np.zeros((num_epochs, num_channels))\n",
    "    cD_mean = np.zeros((num_epochs, num_channels))\n",
    "    cD_std = np.zeros((num_epochs, num_channels))\n",
    "    cD_Energy = np.zeros((num_epochs, num_channels))\n",
    "    Entropy_D = np.zeros((num_epochs, num_channels))\n",
    "    Entropy_A = np.zeros((num_epochs, num_channels))\n",
    "    wfeatures = np.zeros((num_epochs, 7 * num_channels))\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        for j in range(num_channels):\n",
    "            cA, cD = pywt.dwt(epoch[i, j, :], \"coif1\")\n",
    "            # cA_values[i, j, :] = cA\n",
    "            # cD_values[i, j, :] = cD\n",
    "            cA_mean[i, j] = np.mean(cA)\n",
    "            cA_std[i, j] = np.abs(np.std(cA))\n",
    "            cA_Energy[i, j] = np.sum(np.square(cA))\n",
    "            cD_mean[i, j] = np.mean(cD)\n",
    "            cD_std[i, j] = np.abs(np.std(cD))\n",
    "            cD_Energy[i, j] = np.sum(np.square(cD))\n",
    "            Entropy_D[i, j] = np.sum(np.square(cD) * np.log(np.square(cD)))\n",
    "            Entropy_A[i, j] = np.sum(np.square(cA) * np.log(np.square(cA)))\n",
    "\n",
    "    wfeatures[:, 0::7] = cA_mean\n",
    "    wfeatures[:, 1::7] = cA_std\n",
    "    wfeatures[:, 2::7] = cA_Energy\n",
    "    wfeatures[:, 3::7] = cD_mean\n",
    "    wfeatures[:, 4::7] = cD_std\n",
    "    wfeatures[:, 5::7] = cD_Energy\n",
    "    wfeatures[:, 6::7] = Entropy_D + Entropy_A\n",
    "\n",
    "    return wfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectral Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPwelch_epochs(epochs, Fs):\n",
    "  n_epochs, n_channels, n_samples_per_epoch = epochs.shape\n",
    "  BandF = [12, 30, 100]\n",
    "  PMax = np.zeros([n_epochs, n_channels, len(BandF) - 1])\n",
    "\n",
    "  for i in range(n_epochs):\n",
    "    for j in range(n_channels):\n",
    "      f, Psd = signal.welch(epochs[i, j, :], Fs)\n",
    "\n",
    "      if np.any(np.isnan(Psd)):\n",
    "        nonnan_values = Psd[~np.isnan(Psd)]\n",
    "        nan_average = np.mean(nonnan_values)\n",
    "        Psd[np.isnan(Psd)] = nan_average\n",
    "\n",
    "      for k in range(len(BandF) - 1):\n",
    "        fr = np.where((f > BandF[k]) & (f <= BandF[k + 1]))\n",
    "        PMax[i, j, k] = np.max(Psd[fr])\n",
    "\n",
    "  return PMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preporcessed Data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = np.load(f'./data/filtered-sub-{subjectid}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 14, 500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(epoch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "hjorth = hjorth_mean(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hjorth_list = np.concatenate(\n",
    "    (hjorth[0][:, np.newaxis], hjorth[1][:, np.newaxis], hjorth[2][:, np.newaxis]),\n",
    "    axis=1,\n",
    ")\n",
    "display(hjorth_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(837,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(837,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hjorth[0].shape, hjorth[1].shape, hjorth[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kurtosis = kurtosis_feature(epoch_data)\n",
    "display(kurtosis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 98)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wavelet = wavelet_features(epoch_data)\n",
    "display(wavelet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(data):\n",
    "    flattened_data = data.reshape(data.shape[0], -1)\n",
    "    return flattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 14, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "psd = maxPwelch_epochs(epoch_data, 500)\n",
    "display(psd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "psd_2d = flatten(psd)\n",
    "display(psd_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding labels and building the final feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell for single subject\n",
    "labels = np.load(f\"./data/label-sub-{subjectid}.npy\")\n",
    "display(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Feature Vector for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 130)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_vector = np.concatenate(\n",
    "    (\n",
    "      hjorth_list, \n",
    "      # kurtosis[:, np.newaxis], \n",
    "      wavelet, \n",
    "      psd_2d,\n",
    "      labels[:, np.newaxis]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "display(feature_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell when doing feature extration for single subject\n",
    "np.save(f\"./data/hjorth-psd-wavelet-sub-{subjectid}.npy\", feature_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
